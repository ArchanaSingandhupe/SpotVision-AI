{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 180, 180, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 90, 90, 64)   1728        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 90, 90, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 90, 90, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 45, 45, 64)   36864       ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 45, 45, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 45, 45, 64)   4096        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 45, 45, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 45, 45, 64)   36864       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 45, 45, 64)  256         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 45, 45, 256)  16384       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 45, 45, 256)  16384       ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 45, 45, 256)  1024       ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 45, 45, 256)  1024       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 45, 45, 256)  0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 45, 45, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 45, 45, 64)   16384       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 45, 45, 64)  256         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 45, 45, 64)   36864       ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 45, 45, 64)  256         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 45, 45, 256)  16384       ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 45, 45, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 45, 45, 256)  0           ['batch_normalization_12[0][0]', \n",
      "                                                                  're_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 45, 45, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 45, 45, 64)   16384       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 45, 45, 64)  256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 45, 45, 64)   36864       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 45, 45, 64)  256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 45, 45, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 45, 45, 256)  16384       ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 45, 45, 256)  1024       ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 45, 45, 256)  0           ['batch_normalization_15[0][0]', \n",
      "                                                                  're_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 45, 45, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 45, 45, 64)   16384       ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 45, 45, 64)  256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 45, 45, 64)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 45, 45, 64)   36864       ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 45, 45, 64)  256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 45, 45, 64)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 45, 45, 256)  16384       ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 45, 45, 256)  1024       ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 45, 45, 256)  0           ['batch_normalization_18[0][0]', \n",
      "                                                                  're_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 45, 45, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 256)         0           ['re_lu_13[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8)            2056        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 330,952\n",
      "Trainable params: 327,112\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Bottleneck Block for the HRNet model\n",
    "def bottleneck_block(x, filters, stride=1):\n",
    "    shortcut = x\n",
    "    # Main branch\n",
    "    x = layers.Conv2D(filters // 4, 1, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters // 4, 3, strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 1, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Shortcut branch\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "# High-Resolution Block\n",
    "def high_resolution_block(x, filters, num_blocks):\n",
    "    for _ in range(num_blocks):\n",
    "        x = bottleneck_block(x, filters)\n",
    "    return x\n",
    "\n",
    "# Build the HRNet Model\n",
    "def build_hrnet(input_shape=(180, 180, 3), num_classes=8):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Stem Stage\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Stage 1\n",
    "    x = high_resolution_block(x, 256, num_blocks=4)\n",
    "\n",
    "    # Classification Head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the HRNet model\n",
    "model = build_hrnet()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9376 images belonging to 8 classes.\n",
      "Found 2344 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "Batch_size = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and prepare the data with square dimensions and data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(180, 180),\n",
    "    batch_size=Batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(180, 180),\n",
    "    batch_size=Batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "293/293 [==============================] - 345s 1s/step - loss: 0.9881 - accuracy: 0.6521 - val_loss: 1.9392 - val_accuracy: 0.0646\n",
      "Epoch 2/10\n",
      "293/293 [==============================] - 354s 1s/step - loss: 0.9102 - accuracy: 0.6701 - val_loss: 1.0636 - val_accuracy: 0.6618\n",
      "Epoch 3/10\n",
      "293/293 [==============================] - 544s 2s/step - loss: 0.8918 - accuracy: 0.6800 - val_loss: 0.9999 - val_accuracy: 0.6674\n",
      "Epoch 4/10\n",
      "293/293 [==============================] - 626s 2s/step - loss: 0.8619 - accuracy: 0.6860 - val_loss: 1.1951 - val_accuracy: 0.6520\n",
      "Epoch 5/10\n",
      "293/293 [==============================] - 611s 2s/step - loss: 0.8462 - accuracy: 0.6912 - val_loss: 1.7222 - val_accuracy: 0.3943\n",
      "Epoch 6/10\n",
      "293/293 [==============================] - 608s 2s/step - loss: 0.8088 - accuracy: 0.7079 - val_loss: 1.4397 - val_accuracy: 0.6421\n",
      "Epoch 7/10\n",
      "293/293 [==============================] - 605s 2s/step - loss: 0.7873 - accuracy: 0.7150 - val_loss: 1.0424 - val_accuracy: 0.6537\n",
      "Epoch 8/10\n",
      "293/293 [==============================] - 608s 2s/step - loss: 0.7801 - accuracy: 0.7166 - val_loss: 1.4287 - val_accuracy: 0.5407\n",
      "Epoch 9/10\n",
      "293/293 [==============================] - 603s 2s/step - loss: 0.7538 - accuracy: 0.7241 - val_loss: 0.8453 - val_accuracy: 0.7003\n",
      "Epoch 10/10\n",
      "293/293 [==============================] - 598s 2s/step - loss: 0.7432 - accuracy: 0.7343 - val_loss: 0.9732 - val_accuracy: 0.6721\n",
      "74/74 [==============================] - 28s 371ms/step - loss: 0.9726 - accuracy: 0.6719\n",
      "Validation Accuracy: 0.671928346157074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the HRNet model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // Batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // Batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"HRnet_custom.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class MultiHeadAttentionLayer(layers.Layer):\n",
    "    def __init__(self, filters, num_heads=8):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        assert filters % num_heads == 0, \"filters must be divisible by num_heads\"\n",
    "        self.filters = filters\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = filters // num_heads\n",
    "\n",
    "        # Define query, key, value convolutions\n",
    "        self.query_conv = layers.Conv2D(filters, kernel_size=1, dtype='float32')\n",
    "        self.key_conv = layers.Conv2D(filters, kernel_size=1, dtype='float32')\n",
    "        self.value_conv = layers.Conv2D(filters, kernel_size=1, dtype='float32')\n",
    "\n",
    "        # Gamma parameter for residual learning\n",
    "        self.gamma = tf.Variable(0.0, dtype='float32')\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth)\"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]  # Dynamic batch size\n",
    "        residual = x  # Skip connection\n",
    "\n",
    "        # Generate query, key, and value feature maps\n",
    "        query = self.query_conv(x)\n",
    "        key = self.key_conv(x)\n",
    "        value = self.value_conv(x)\n",
    "\n",
    "        # Split heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # Calculate attention scores\n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        scores = tf.nn.softmax(scores, axis=-1)\n",
    "\n",
    "        # Apply the attention scores to the value map\n",
    "        out = tf.matmul(scores, value)\n",
    "        out = tf.transpose(out, perm=[0, 2, 1, 3])\n",
    "        out = tf.reshape(out, (batch_size, tf.shape(x)[1], tf.shape(x)[2], self.filters))\n",
    "\n",
    "        # Add the attention results to the original feature maps\n",
    "        out = self.gamma * out + residual\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 256, 256, 32) 896         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256, 256, 32) 128         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 128, 128, 64) 18496       batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 64) 256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 64) 2112        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 128, 128, 64) 256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 64) 256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128, 128, 64) 0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 128, 128, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 64, 64, 128)  73856       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 64, 64, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 64, 128)  8320        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 64, 128)  512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 128)  512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 128)  0           batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 64, 64, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_layer_5 (M (None, 64, 64, 128)  49537       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 256)  295168      multi_head_attention_layer_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 256)  1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 256)  590080      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 256)  33024       multi_head_attention_layer_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 256)  1024        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 256)  0           batch_normalization_31[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 32, 32, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            1032        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,295,433\n",
      "Trainable params: 1,292,681\n",
      "Non-trainable params: 2,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    \"\"\"Residual Block with skip connection\"\"\"\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "def build_attention_cnn(input_shape=(512, 512, 3), num_classes=8):\n",
    "    inputs = layers.Input(shape=input_shape, dtype='float32')\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    x = residual_block(x, 64, stride=2)\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    x = residual_block(x, 128, stride=2)\n",
    "\n",
    "    # Add Multi-Head Attention Layer with Skip Connections\n",
    "    x = MultiHeadAttentionLayer(128, num_heads=8)(x)\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    x = residual_block(x, 256, stride=2)\n",
    "\n",
    "    # Global Pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Dense Classification Head\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, predictions)\n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the multi-head attention-enhanced CNN\n",
    "model = build_attention_cnn()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9376 images belonging to 8 classes.\n",
      "Found 2344 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and prepare the data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(180, 180),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Labels (First 5): [[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sample_images, sample_labels = next(train_generator)\n",
    "print(\"Sample Labels (First 5):\", sample_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available devices\n",
    "print(\"Available GPU devices:\", tf.config.experimental.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "293/293 [==============================] - 201s 653ms/step - loss: 0.9986 - accuracy: 0.6555 - val_loss: 1.4851 - val_accuracy: 0.4229\n",
      "Epoch 2/30\n",
      "293/293 [==============================] - 230s 785ms/step - loss: 0.8833 - accuracy: 0.6804 - val_loss: 1.0207 - val_accuracy: 0.6704\n",
      "Epoch 3/30\n",
      "293/293 [==============================] - 191s 650ms/step - loss: 0.8299 - accuracy: 0.6981 - val_loss: 0.9599 - val_accuracy: 0.6866\n",
      "Epoch 4/30\n",
      "293/293 [==============================] - 218s 744ms/step - loss: 0.8057 - accuracy: 0.7051 - val_loss: 0.7855 - val_accuracy: 0.7102\n",
      "Epoch 5/30\n",
      "293/293 [==============================] - 213s 727ms/step - loss: 0.7734 - accuracy: 0.7170 - val_loss: 0.8422 - val_accuracy: 0.7012\n",
      "Epoch 6/30\n",
      "293/293 [==============================] - 212s 722ms/step - loss: 0.7605 - accuracy: 0.7214 - val_loss: 0.8247 - val_accuracy: 0.7029\n",
      "Epoch 7/30\n",
      "293/293 [==============================] - 210s 717ms/step - loss: 0.7423 - accuracy: 0.7274 - val_loss: 0.9409 - val_accuracy: 0.6918\n",
      "Epoch 8/30\n",
      "293/293 [==============================] - 213s 725ms/step - loss: 0.7364 - accuracy: 0.7297 - val_loss: 1.5857 - val_accuracy: 0.6640\n",
      "Epoch 9/30\n",
      "293/293 [==============================] - 212s 725ms/step - loss: 0.7275 - accuracy: 0.7339 - val_loss: 0.8209 - val_accuracy: 0.7110\n",
      "Epoch 10/30\n",
      "293/293 [==============================] - 175s 595ms/step - loss: 0.7187 - accuracy: 0.7354 - val_loss: 0.7686 - val_accuracy: 0.7085\n",
      "Epoch 11/30\n",
      "293/293 [==============================] - 228s 778ms/step - loss: 0.7162 - accuracy: 0.7402 - val_loss: 0.8140 - val_accuracy: 0.7140\n",
      "Epoch 12/30\n",
      "293/293 [==============================] - 233s 795ms/step - loss: 0.6983 - accuracy: 0.7455 - val_loss: 0.9394 - val_accuracy: 0.6854\n",
      "Epoch 13/30\n",
      "293/293 [==============================] - 222s 756ms/step - loss: 0.6957 - accuracy: 0.7495 - val_loss: 0.7271 - val_accuracy: 0.7269\n",
      "Epoch 14/30\n",
      "293/293 [==============================] - 176s 601ms/step - loss: 0.6785 - accuracy: 0.7501 - val_loss: 0.7365 - val_accuracy: 0.7359\n",
      "Epoch 15/30\n",
      "293/293 [==============================] - 163s 556ms/step - loss: 0.6684 - accuracy: 0.7506 - val_loss: 0.8966 - val_accuracy: 0.7153\n",
      "Epoch 16/30\n",
      "293/293 [==============================] - 251s 856ms/step - loss: 0.6649 - accuracy: 0.7547 - val_loss: 0.7836 - val_accuracy: 0.7132\n",
      "Epoch 17/30\n",
      "293/293 [==============================] - 239s 814ms/step - loss: 0.6546 - accuracy: 0.7634 - val_loss: 0.7134 - val_accuracy: 0.7350\n",
      "Epoch 18/30\n",
      "293/293 [==============================] - 230s 784ms/step - loss: 0.6593 - accuracy: 0.7576 - val_loss: 0.8331 - val_accuracy: 0.7359\n",
      "Epoch 19/30\n",
      "293/293 [==============================] - 244s 833ms/step - loss: 0.6412 - accuracy: 0.7641 - val_loss: 0.7054 - val_accuracy: 0.7363\n",
      "Epoch 20/30\n",
      "293/293 [==============================] - 232s 789ms/step - loss: 0.6302 - accuracy: 0.7670 - val_loss: 0.7077 - val_accuracy: 0.7513\n",
      "Epoch 21/30\n",
      "293/293 [==============================] - 234s 797ms/step - loss: 0.6419 - accuracy: 0.7611 - val_loss: 0.7221 - val_accuracy: 0.7196\n",
      "Epoch 22/30\n",
      "293/293 [==============================] - 224s 765ms/step - loss: 0.6265 - accuracy: 0.7701 - val_loss: 0.6838 - val_accuracy: 0.7461\n",
      "Epoch 23/30\n",
      "293/293 [==============================] - 244s 831ms/step - loss: 0.6195 - accuracy: 0.7709 - val_loss: 0.7235 - val_accuracy: 0.7380\n",
      "Epoch 24/30\n",
      "293/293 [==============================] - 237s 809ms/step - loss: 0.6157 - accuracy: 0.7709 - val_loss: 0.7823 - val_accuracy: 0.7256\n",
      "Epoch 25/30\n",
      "293/293 [==============================] - 236s 804ms/step - loss: 0.6121 - accuracy: 0.7730 - val_loss: 0.8430 - val_accuracy: 0.7307\n",
      "Epoch 26/30\n",
      "293/293 [==============================] - 237s 808ms/step - loss: 0.6059 - accuracy: 0.7738 - val_loss: 0.7730 - val_accuracy: 0.7444\n",
      "Epoch 27/30\n",
      "293/293 [==============================] - 241s 821ms/step - loss: 0.5987 - accuracy: 0.7736 - val_loss: 0.8066 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "293/293 [==============================] - 236s 804ms/step - loss: 0.5872 - accuracy: 0.7816 - val_loss: 0.9322 - val_accuracy: 0.7205\n",
      "Epoch 29/30\n",
      "293/293 [==============================] - 239s 817ms/step - loss: 0.5923 - accuracy: 0.7772 - val_loss: 0.8538 - val_accuracy: 0.7192\n",
      "Epoch 30/30\n",
      "293/293 [==============================] - 236s 805ms/step - loss: 0.5917 - accuracy: 0.7838 - val_loss: 0.7191 - val_accuracy: 0.7303\n"
     ]
    }
   ],
   "source": [
    "# Train the multi-head attention-enhanced CNN model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // 32\n",
    ")\n",
    "# 293/293 [==============================] - 103s 350ms/step - loss: 1.0234 - accuracy: 0.6448 - val_loss: 1.8943 - val_accuracy: 0.1396\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44622bf898d20f3fc9a57c54d189541ce49c08446fc18f7c26ba3d242a23814f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
